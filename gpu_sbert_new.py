import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util
from collections import defaultdict

# ======================================================================================
# G≈Å√ìWNY I OSTATECZNY BLOK KODU DO WERYFIKACJI I KOREKTY 3000 ETYKIET
# ======================================================================================

# Krok 1: Przygotowanie danych i wczytanie modelu
print("üîÑ Przygotowywanie danych i wczytywanie modelu...")
# Upewnij siƒô, ≈ºe model jest wczytany.
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = SentenceTransformer('all-MiniLM-L6-v2', device=device)
print(f"Model wczytany. Weryfikacja bƒôdzie wykonana na: {device.upper()}")

# Wybierz tylko te wiersze z Twojego DataFrame, kt√≥re majƒÖ etykietƒô
df_labeled = df.dropna(subset=['label']).copy()

# Wyodrƒôbnij unikalne etykiety, kt√≥re bƒôdƒÖ pulƒÖ kandydat√≥w
candidate_labels = df_labeled['label'].unique().tolist()
print(f"‚úÖ Znaleziono {len(df_labeled)} oznaczonych wierszy i {len(candidate_labels)} unikalnych etykiet do weryfikacji.")

# Krok 2: Tworzenie wektor√≥w (embeddings) dla tekst√≥w i etykiet
print("\nüîÑ Przetwarzanie tekst√≥w i etykiet na wektory numeryczne...")
# To jest najd≈Çu≈ºszy krok, ale na GPU p√≥jdzie szybko.
text_embeddings = model.encode(df_labeled['text'].astype(str).tolist(), batch_size=256, show_progress_bar=True)
label_embeddings = model.encode(candidate_labels, batch_size=256, show_progress_bar=True)
print("‚úÖ Teksty i etykiety przetworzone.")

# Krok 3: Znalezienie najlepszej etykiety dla ka≈ºdego tekstu
print("\nüîÑ Sprawdzanie ka≈ºdego wiersza i szukanie najlepszego dopasowania...")
# Oblicz podobie≈Ñstwo ka≈ºdego tekstu do WSZYSTKICH mo≈ºliwych etykiet
similarity_scores = util.cos_sim(text_embeddings, label_embeddings)

# Przygotuj listy na nowe kolumny
model_suggestions = []
confidence_scores = []

# Przejd≈∫ przez ka≈ºdy wiersz i znajd≈∫ najlepszy wynik
for i in range(len(df_labeled)):
    best_match_index = torch.argmax(similarity_scores[i]).item()
    best_label = candidate_labels[best_match_index]
    best_score = similarity_scores[i][best_match_index].item() * 100
    
    model_suggestions.append(best_label)
    confidence_scores.append(f"{best_score:.2f}%")

# Krok 4: Dodanie nowych kolumn do DataFrame z etykietami
df_labeled['sugestia_modelu'] = model_suggestions
df_labeled['pewnosc_sugestii_%'] = confidence_scores

# Stw√≥rz kolumnƒô 'nowy_label', kt√≥ra pokazuje tylko zmiany
# np.where(warunek, warto≈õƒá_je≈õli_prawda, warto≈õƒá_je≈õli_fa≈Çsz)
df_labeled['nowy_label'] = np.where(
    df_labeled['label'] != df_labeled['sugestia_modelu'], # warunek: oryginalna etykieta jest inna ni≈º sugestia
    df_labeled['sugestia_modelu'],                        # je≈õli tak, wstaw sugestiƒô
    None                                                 # je≈õli nie, zostaw puste (None)
)
print("‚úÖ Analiza zako≈Ñczona. Dodano nowe kolumny.")

# Krok 5: Aktualizacja oryginalnego DataFrame 'df'
# U≈ºyjemy .update(), aby przenie≈õƒá nowe kolumny do g≈Ç√≥wnego DataFrame, dopasowujƒÖc po indeksie
df.update(df_labeled)

# Krok 6: Wy≈õwietlenie raportu ze zmianami
print("\n\n--- WYNIKI WERYFIKACJI ---")
# Wybierz tylko te wiersze, gdzie model znalaz≈Ç b≈ÇƒÖd
df_corrections = df[df['nowy_label'].notna()].copy()

if df_corrections.empty:
    print("‚úÖ Model nie znalaz≈Ç ≈ºadnych etykiet do poprawy. Wszystkie 3000 sƒÖ zgodne z jego sugestiami.")
else:
    print(f"‚úÖ Model znalaz≈Ç {len(df_corrections)} etykiet do poprawy.")
    print("Poni≈ºej znajduje siƒô lista tych wierszy:")
    
    # Ustawienie opcji wy≈õwietlania, ≈ºeby tekst nie by≈Ç ucinany
    pd.set_option('display.max_colwidth', None)
    
    # Wy≈õwietl najwa≈ºniejsze kolumny dla wierszy, kt√≥re zosta≈Çy zmienione
    print(df_corrections[['text', 'label', 'sugestia_modelu', 'pewnosc_sugestii_%']])
